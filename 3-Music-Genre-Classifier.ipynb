{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TirendazAcademy/An-LLM-App-with-Chainlit/blob/main/3-Music-Genre-Classifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YcmbkLrHpxjL"
      },
      "source": [
        "# Installing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XSOyqDYRgl9C"
      },
      "source": [
        "Let's install the trasformers library."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U18FRzPifcqP"
      },
      "outputs": [],
      "source": [
        "!pip install -qU git+https://github.com/huggingface/transformers\n",
        "!pip install -qU git+https://github.com/huggingface/datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fii1QHHhhDyP"
      },
      "outputs": [],
      "source": [
        "import transformers, datasets\n",
        "print(\"The transformers version:\", transformers.__version__)\n",
        "print(\"The datasets version:\", datasets.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FhpbB00ihLKJ"
      },
      "source": [
        "Next, let's load the dataset we'll use."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d-ewZRfihIif"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "minds = load_dataset(\"PolyAI/minds14\", name=\"en-AU\", split=\"train\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fFgXN0XRieKJ"
      },
      "source": [
        "#  Pre-trained models and datasets for audio classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ihmBexMDh7sM"
      },
      "source": [
        "Then let's create our pipeline:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vGMI7ZZdhQPX"
      },
      "outputs": [],
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "classifier = pipeline(\n",
        "    \"audio-classification\",\n",
        "    model=\"anton-l/xtreme_s_xlsr_300m_minds14\",\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ly86sGtkiFW8"
      },
      "source": [
        "Finally, we can pass a sample to the classification pipeline to make a prediction:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RDpRcgfyiF1Q"
      },
      "outputs": [],
      "source": [
        "classifier(minds[0][\"audio\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bI2gvUSDiWBF"
      },
      "source": [
        "## Speech Commands"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VDjDRxSYjyGJ"
      },
      "source": [
        "First, let's load the dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BGR9t69HiXkv"
      },
      "outputs": [],
      "source": [
        "speech_commands = load_dataset(\n",
        "    \"speech_commands\", \"v0.02\", split=\"validation\", streaming=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gWDQacr-j5Rn"
      },
      "outputs": [],
      "source": [
        "sample = next(iter(speech_commands))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nGM-i1Ltj_Jm"
      },
      "outputs": [],
      "source": [
        "sample"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0-fppD-tkN0r"
      },
      "source": [
        " Let's load an official Audio Spectrogram Transformer checkpoint fine-tuned on the Speech Commands dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oEE_IfcKkPbQ"
      },
      "outputs": [],
      "source": [
        "classifier = pipeline(\n",
        "    \"audio-classification\", model=\"MIT/ast-finetuned-speech-commands-v2\"\n",
        ")\n",
        "classifier(sample[\"audio\"].copy())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PsRkxBYfkiJf"
      },
      "source": [
        "As you can see, the prediction of our model is backward. Let me take a listen to the sample and verify this is prediction:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FFaD2I1TkvVZ"
      },
      "outputs": [],
      "source": [
        "from IPython.display import Audio\n",
        "\n",
        "Audio(sample[\"audio\"][\"array\"], rate=sample[\"audio\"][\"sampling_rate\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J6GDtVwqmcHi"
      },
      "source": [
        "## Language Identification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vSdiS8uBmk9G"
      },
      "source": [
        "Language identification (LID) is the task of identifying the language spoken in an audio sample from a list of candidate languages systems in 102 languages."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LgbUTNS_k3In"
      },
      "outputs": [],
      "source": [
        "fleurs = load_dataset(\"google/fleurs\", \"all\", split=\"validation\", streaming=True, trust_remote_code=True)\n",
        "sample = next(iter(fleurs))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zGTmNdnznDxb"
      },
      "source": [
        "Next, let's create our pipeline."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cYxYj7iqmwGK"
      },
      "outputs": [],
      "source": [
        "classifier = pipeline(\n",
        "    \"audio-classification\", model=\"sanchit-gandhi/whisper-medium-fleurs-lang-id\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "doToFKYdns9X"
      },
      "source": [
        "We can then pass the audio through our classifier and generate a prediction:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-Ge7On14nqPo"
      },
      "outputs": [],
      "source": [
        "classifier(sample[\"audio\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jyMumlaooAuU"
      },
      "source": [
        "## Zero-Shot Audio Classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QeFgPOr8oBn8"
      },
      "outputs": [],
      "source": [
        "dataset = load_dataset(\"ashraq/esc50\", split=\"train\", streaming=True)\n",
        "audio_sample = next(iter(dataset))[\"audio\"][\"array\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XK863iorokEt"
      },
      "outputs": [],
      "source": [
        "candidate_labels = [\"Sound of a dog\", \"Sound of vacuum cleaner\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iDvnYBVco2gM"
      },
      "outputs": [],
      "source": [
        "classifier = pipeline(\n",
        "    task=\"zero-shot-audio-classification\", model=\"laion/clap-htsat-unfused\"\n",
        ")\n",
        "classifier(audio_sample, candidate_labels=candidate_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EdvrK-vqpI38"
      },
      "outputs": [],
      "source": [
        "Audio(audio_sample, rate=16000)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": [],
      "authorship_tag": "ABX9TyPBO0ZONDaQSxyB8kxVYZPQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}